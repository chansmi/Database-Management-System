---
title: "Chandler Practicum 2"
output: html_notebook
---
# Be Kind, this took a long time haha. Also, instructions said to use Date Created and Journal Published, this lead to some strange results.

```{r}
library(XML)
library(DBI)
library(knitr)
library(sqldf)
library(RMariaDB)
library(tidyverse)
library(methods)
library(lubridate)
library(sqldf)
library(magrittr)
library(ggplot2)
```

# Part 1 (40 pts) Load XML
## In Part 1 you create a normalized relational OLTP database and populate it with data from an XML document. In Part 2 you will add to the normalized schema fact tables and turn the normalized schema into a denormalized schema suitable for OLAP. In Part 3 you'll use the OLAP star/snowflake schema to do some (simple) data mining.

## (5 pts) Create a normalized relational schema that contains the following entities/tables: Articles, Journals, Authors. Use the XML document to determine the appropriate attributes (fields/columns) for the entities (tables). While there may be other types of publications in the XML, you only need to deal with articles in journals. Create appropriate primary and foreign keys. Where necessary, add surrogate keys. Include an image of an ERD showing your model in your R Notebook. For articles you should minimally store the article title (<ArticleTitle>) and date created (<DateCreated>); for journals store the journal name/title, volume, issue, and publication date. For authors you should store last name, first name, initial, and affiliation.

[ERD Diagram for Books ]https://imgur.com/a/l3P3Gcg)

```{r}
knitr::include_graphics("https://imgur.com/a/l3P3Gcg")
```

## (5 pts) Realize the relational schema in SQLite (place the CREATE TABLE statements into SQL chunks in your R Notebook). Use the appropriate tag for publication date. See this link (Links to an external site.) for information.

#Connect to the MYSQL DB
```{r}
localuserpassword <- "SomethingDifficult"
dbcon <- dbConnect(RMariaDB::MariaDB(), user='PubMed_user', password=localuserpassword, dbname='pubmed', host='localhost')
```

```{sql connection=dbcon}
DROP TABLE IF EXISTS AuthJoin
```

```{sql connection=dbcon}
DROP TABLE IF EXISTS Article
```

```{sql connection=dbcon}
DROP TABLE IF EXISTS SubmissionDate
```

```{sql connection=dbcon}
DROP TABLE IF EXISTS AffJoin
```

```{sql connection=dbcon}
DROP TABLE IF EXISTS Author
```

```{sql connection=dbcon}
DROP TABLE IF EXISTS Affiliation
```

```{sql connection=dbcon}
DROP TABLE IF EXISTS JournalPub
```

```{sql connection=dbcon}
DROP TABLE IF EXISTS Journal
```


#Create tables for relational schema

## JOURNAL
```{sql connection=dbcon}
CREATE TABLE Journal(
  jID VARCHAR(20),
  ISSN VARCHAR(20),
  Volume INTEGER,
  Issue INTEGER,
  PubDate VARCHAR(20),
  JournalTitle VARCHAR(100),
  CONSTRAINT ISSN_pk PRIMARY KEY (ISSN)
)
```

## JournalPUB
```{sql connection=dbcon}
CREATE TABLE JournalPub(
  PubID VARCHAR(20),
  MONTH VARCHAR(20),
  YEAR INTEGER,
  DayNum INTEGER,
  ISSN VARCHAR(20),
  CONSTRAINT pubID_pk PRIMARY KEY (PubID),
  CONSTRAINT ISSN_fk FOREIGN KEY(ISSN) REFERENCES Journal(ISSN)
)
```

## AUTHOR
```{sql connection=dbcon}
CREATE TABLE Author(
  aid VARCHAR(20),
  LastName TEXT,
  FirstName TEXT,
  Initials TEXT,
  CONSTRAINT aid_pk PRIMARY KEY (aid)
)
```
## AFFILIATION
```{sql connection=dbcon}
CREATE TABLE Affiliation(
  fid VARCHAR(20) UNIQUE,
  Affiliation TEXT,
  CONSTRAINT fid_pk PRIMARY KEY (fid)
)
```
<!-- ## AFFJOIN -->
<!-- ```{sql connection=dbcon} -->
<!-- CREATE TABLE AffJoin( -->
<!--   fid VARCHAR(20) UNIQUE, -->
<!--   aid VARCHAR(20) UNIQUE, -->
<!--   CONSTRAINT Affiliation_fk FOREIGN KEY(fid) REFERENCES Affiliation(fid), -->
<!--   CONSTRAINT Author_fk FOREIGN KEY(aid) REFERENCES Author(aid) -->
<!-- ) -->
<!-- ``` -->
## PUBDATE
```{sql connection=dbcon}
CREATE TABLE SubmissionDate(
  pid VARCHAR(20) UNIQUE,
  Year INTEGER,
  Month INTEGER,
  Day INTEGER,
  CONSTRAINT pid_pk PRIMARY KEY (pid)
)
```

## ARTICLE
```{sql connection=dbcon}
CREATE TABLE Article(
  rid VARCHAR(20) UNIQUE,
  ArticleTitle TEXT,
  ArticleDate TEXT,
  pid VARCHAR(20) UNIQUE,
  ISSN VARCHAR(20),
  CONSTRAINT rid_pk PRIMARY KEY (rid),
  -- CONSTRAINT pid_fk FOREIGN KEY(pid) REFERENCES SubmissionDate(pid),
  CONSTRAINT Article_ISSN_fk FOREIGN KEY(ISSN) REFERENCES Journal(ISSN)
)
```

<!-- ## AUTHJOIN -->
<!-- ```{sql connection=dbcon} -->
<!-- CREATE TABLE AuthJoin( -->
<!--   rid VARCHAR(20) UNIQUE, -->
<!--   aid VARCHAR(20) UNIQUE, -->
<!--   CONSTRAINT Article_fk FOREIGN KEY(rid) REFERENCES Article(rid), -->
<!--   CONSTRAINT Author2_fk FOREIGN KEY(aid) REFERENCES Author(aid) -->
<!-- ) -->
<!-- ``` -->

# (30 pts) Extract and transform the data from the XML and then load into the appropriate tables in the database. You cannot (directly and solely) use xmlToDataFrame but instead must parse the XML node by node using a combination of node-by-node tree traversal and XPath. It is not feasible to use XPath to extract all journals, then all authors, etc. as some are missing and won't match up. You will need to iterate through the top-level nodes. While outside the scope of the course, this task could also be done through XSLT. Do not store duplicate authors or journals. For dates, you need to devise a conversion scheme, document your decision, and convert all dates to your encoding scheme. (Links to an external site.)

```{r warning=FALSE}
remove(JournalPubDF, JournalDF, Affiliation.DF, AuthorDF, AffJoinDF, SubmissionDateDF, ArticleDF, AuthJoinDF)
```

```{r warning=FALSE}
remove(Affiliation, Affiliation.df, AffiliationIntermediate, AffJoin.df, Article.df, ArticleIntermediate, AsList, AuthJoin.df, author, Author.df, Authors, Journal.df, JournalIntermediate, JournalNode, JournalPub.df, JournalPubDate, JournalTest, MedlineCitation.df, PMID, Pubdate, PubDate.df, PubDateIntermediate, temp1, test)
```


#Create Dataframes
```{r}
JournalPubDF <- data.frame( PubId = integer(), 
                            Month = integer(), 
                            Year = integer(),
                            DayNum = integer(),
                            ISSN = character(),
                            stringsAsFactors = F)

JournalDF <- data.frame ( jID = character(),
                          ISSN = character(),
                          Volume = integer(),
                          Issue = integer(),
                          PubDate = character(),
                          JournalTitle = character(),
                          stringsAsFactors = F)

AffiliationDF <- data.frame (fid = integer(),
                          Affiliation = character(),
                          stringsAsFactors = F)

AuthorDF <- data.frame (aid = integer(),
                          LastName = character(),
                          FirstName = character(),
                          Initials = character(),
                          stringsAsFactors = F)

# AffJoinDF <- data.frame (aid = integer(),
#                           fid = integer(),
#                           stringsAsFactors = F)

SubmissionDateDF <- data.frame (pid = integer(),
                            Year = integer(),
                            Month = integer(),
                            Day = integer(),
                          stringsAsFactors = F)

ArticleDF <- data.frame (rid = character(),
                       ArticleTitle = character(),
                       ArticleDate = character(),
                       pid = integer(),
                       ISSN = integer(),
                       stringsAsFactors = F)

# AuthJoinDF <- data.frame (aid = integer(),
#                           rid = integer(),
#                           stringsAsFactors = F)

```

#Helper functions for parsing
#Parse the XML
```{r}
dataset <- "pubmed_sample.xml"

# Reading the XML file and parse into DOM
xmlDOM <- xmlParse(file = dataset) #added tree for learning

# get the root node of the DOM tree
r <- xmlRoot(xmlDOM)
#z <- xmlAttrs(xmlRoot(xmlDOM))
#xmlAttrs(xmlRoot(xmlDOM)[["variables"]])
PAnum <- xmlSize(r)
```
# there are 19 <PubmedArticle>

#Row Exists: from Lecture, use to ensure no duplicates
```{r}
rowExists <- function (aRow, aDF)
{
  # check if that address is already in the data frame
  n <- nrow(aDF)
  c <- ncol(aDF)
  
  if (n == 0)
  {
    # data frame is empty, so can't exist
    return(0)
  }
  
  for (a in 1:n)
  {
    # check if all columns match for a row; ignore the aID column
    if (all(aDF[a,] == aRow[1,]))
    {
      # found a match; return it's ID
      return(a)
    }
  }
  
  # none matched
  return(0)
}
```

```{r}
substrRight <- function(x, n){
  substr(x, nchar(x)-n+1, nchar(x))
}
```


#Parse JournalPub
```{r}
parseJournalPub <- function (aJournalNode)
{
  
  JournalIssue <- xmlChildren(aJournalNode)$JournalIssue
  Date <- xmlChildren(JournalIssue)$PubDate
  
   if(xmlSize(Date) >= 2){
     Year1 <- xmlChildren(Date)$Year
     Year <- xmlToList(xmlChildren(Date)$Year)
    
     Month1 <- xmlChildren(Date)$Month
     Month <- xmlToList(xmlChildren(Date)$Month)
     
     Unformatted <- "NA"
     
   } else {
       dateList <- xmlToList(Date)
       Unformatted <- dateList
       if(nchar(dateList) > 4){
       Month <- substrRight(dateList, 3)
       } else { Month <- "NA"}
       Year <- substr(dateList, 1, 4)
   }
  
   if(Month == "Jan"){ Month <- 1}
   if(Month == "Feb"){ Month <- 2}
   if(Month == "Mar"){ Month <- 3}
   if(Month == "Apr"){ Month <- 4}
   if(Month == "May"){ Month <- 5}
   if(Month == "Jun"){ Month <- 6}
   if(Month == "Jul"){ Month <- 7}
   if(Month == "Aug"){ Month <- 8}
   if(Month == "Sep"){ Month <- 9}
   if(Month == "Oct"){ Month <- 10}
   if(Month == "Nov"){ Month <- 11}
   if(Month == "Dec"){ Month <- 12}
   if(Month == "NA"){ Month <- 12}

  
   
  
  ISSN1 <- xmlChildren(aJournalNode)$ISSN
  ISSN2 <- xmlChildren(ISSN1)$text
  ISSN <- xmlToList(ISSN2)
  PubID <- "IPA"
  DayNum = 30
  
   newJournalPub.df <- data.frame(  PubID, Month, Year, DayNum, ISSN,stringsAsFactors = F)
  
   return(newJournalPub.df)
}
```

#Parse Journal No duplicates
```{r}
parseJournal <- function (aJournalNode)
{
  
  ISSN1 <- xmlChildren(aJournalNode)$ISSN
  ISSN2 <- xmlChildren(ISSN1)$text
  ISSN <- xmlToList(ISSN2)

  JournalIssue <- xmlChildren(aJournalNode)$JournalIssue
  Volume1 <- xmlChildren(JournalIssue)$Volume
  Volume <- xmlToList(Volume1)
  
  Issue1 <- xmlChildren(JournalIssue)$Issue
  Issue <- xmlToList(Issue1)
  
  PubDate <- "test" #will be a FK
  
  jID = i
  
  JournalTitle1 <- xmlChildren(aJournalNode)$Title
  JournalTitle <- xmlToList(JournalTitle1)

  newJournal.df <- data.frame( jID, ISSN, Volume, Issue, PubDate,  JournalTitle, 
                           stringsAsFactors = F)
    
  return(newJournal.df)
}
```

# Parse Affiliation - this will need to be optional
```{r}
parseAffiliation <- function (anArticleNode)
{
  
  AuthorList <- xmlChildren(anArticleNode)$AuthorList
  Author <- xmlChildren(AuthorList)$Author
  Affiliation1 <- xmlChildren(Author)$Affiliation
  Affiliation <- xmlToList(Affiliation1)
  #fid = Affiliation

  newAffiliationDF <- data.frame( Affiliation, Affiliation, stringsAsFactors = F)
  
  return(newAffiliationDF)
}
```

# Affiliation Join
```{r}
parseAffiliationJoin <- function (anArticleNode)
{
  AuthorList <- xmlChildren(anArticleNode)$AuthorList
  Author <- xmlChildren(AuthorList)$Author
  Affiliation1 <- xmlChildren(Author)$Affiliation
  Affiliation <- xmlToList(Affiliation1)
  fid <-  Affiliation
 
  n <- xmlSize(AuthorList)

  # extract each of the <Item> nodes under <Items>
  for (m in 1:n) #This doesn't iterate yet but could be useful
  {
     authorSelect <- AuthorList[m]
     author <- authorSelect$Author
     
     LastName2 <- xmlChildren(author)$LastName
     LastName <- xmlToList(LastName2)
     if(is_null(LastName)==TRUE){
       LastName = ""
     } 
     aid <- LastName
     
}
  newAffiliationJoinDF <- data.frame( fid, aid, stringsAsFactors = F)
  
  return(newAffiliationJoinDF)
}
```

#Parse Authjoin
```{r}
parseAuthJoin <- function (anArticleNode)
{
  
 MedlineCitation <- xmlChildren(anArticleNode)$MedlineCitation
 Article <- xmlChildren(MedlineCitation)$Article
 Title <- xmlChildren(Article)$ArticleTitle
 ArticleTitle <- xmlToList(Title)
 
 rid <- ArticleTitle
  
    AuthorList <- xmlChildren(Article)$AuthorList
  n <- xmlSize(AuthorList)

  # extract each of the <Item> nodes under <Items>
  for (m in 1:n) #This doesn't iterate yet but could be useful
  {
     authorSelect <- AuthorList[m]
     author <- authorSelect$Author
     
     LastName2 <- xmlChildren(author)$LastName
     LastName <- xmlToList(LastName2)
     if(is_null(LastName)==TRUE){
       LastName = ""
     } 
     aid <- LastName
     
}
  newAffiliationJoinDF <- data.frame( fid, aid, stringsAsFactors = F)
  
  return(newAffiliationJoinDF)
}
```

# Parse Author - no duplicates
```{r}
parseAuthors <- function (anAuthorNode)
{
  
  newAuthor.df <- data.frame (
                          LastName = character(),
                          FirstName = character(),
                          Initials = character(),
                          stringsAsFactors = F)
 
  AuthorList <- xmlChildren(Article)$AuthorList
  n <- xmlSize(AuthorList)

  # extract each of the <Item> nodes under <Items>
  for (m in 1:n) #This doesn't iterate yet but could be useful
  {
     authorSelect <- AuthorList[m]
     author <- authorSelect$Author
     
     LastName2 <- xmlChildren(author)$LastName
     LastName <- xmlToList(LastName2)
     if(is_null(LastName)==TRUE){
       LastName = ""
     } 
    
     FirstName1 <- xmlChildren(author)$ForeName
     FirstName <- xmlToList(FirstName1)
     if(is_null(FirstName)==TRUE){
       FirstName = ""
     } 
    
     Initials1 <- xmlChildren(author)$Initials
     Initials <- xmlToList(Initials1)
     if(is_null(Initials)==TRUE){
       Initials = ""
     } 
  
      newAuthor.df[m,2] <- LastName
      newAuthor.df[m,3] <- FirstName
      newAuthor.df[m,4] <- Initials
    #   
      #newAuthor.df <- data.frame( LastName, FirstName, Initials, stringsAsFactors = F)

     }
  return(newAuthor.df)
}
```

#SubmissionDate
```{r}
parseSubmissionDate <- function (aPubDateNode)
{
  
  DateCreated <- xmlChildren(aPubDateNode)$DateCreated
    Year1 <- xmlChildren(DateCreated)$Year
    Year <- xmlToList(Year1)  
  
    Month1 <- xmlChildren(DateCreated)$Month
    Month <- xmlToList(Month1)
    
    Day1 <- xmlChildren(DateCreated)$Day
    Day <- xmlToList(Day1)
  
    # pid = 'S' + ISSN
    pid = i
    
  ISSN2<- xmlChildren(Journal)$ISSN
  ISSN3 <- xmlChildren(ISSN2)$text
  ISSN <- xmlToList(ISSN3)
  
   newSubmissionDateDF <- data.frame( pid, Year, Month, Day, stringsAsFactors = F)
  
  return(newSubmissionDateDF)
}
```

#Article
```{r}
parseArticle <- function (anArticleNode)
{
 
 MedlineCitation <- xmlChildren(anArticleNode)$MedlineCitation
 Article <- xmlChildren(MedlineCitation)$Article
 Title <- xmlChildren(Article)$ArticleTitle
 ArticleTitle <- xmlToList(Title)
 
 rid <- ArticleTitle

  # Child P
 PubmedData <- xmlChildren(anArticleNode)$PubmedData
 ArticleIdList <- xmlChildren(PubmedData)$ArticleIdList
 ArticleId <- xmlChildren(ArticleIdList)$ArticleId
 #rid <- xmlToList(ArticleId)
 
 
  ISSN1 <- xmlChildren(Article)$Journal
  ISSN2<- xmlChildren(Journal)$ISSN
  ISSN3 <- xmlChildren(ISSN2)$text
  ISSN <- xmlToList(ISSN3)
  
  ArticleDate = "tempDate"
  #pid = 'S' + ISSN
  pid = i

  newArticle.df <- data.frame( rid, ArticleTitle, ArticleDate,  pid, ISSN,  stringsAsFactors = F)
    
  return(newArticle.df)
}
```

# Go through each node
```{r}
for (i in 1:PAnum){
  #for each node
 aPA <- r[[i]]
 #child medline
 MedlineCitation <- xmlChildren(aPA)$MedlineCitation
 #Child Article
 Article <- xmlChildren(MedlineCitation)$Article
 #Child Journal
 Journal <- xmlChildren(Article)$Journal
 # Child P
 PubmedData <- xmlChildren(aPA)$PubmedData
 
 #Helper functions
  #JOURNALPUB
  JournalPubDate <- parseJournalPub(Journal)
  JPNode <- nrow(JournalPubDF) + 1
  JournalPubDF[JPNode,1:ncol(JournalPubDF)] <- JournalPubDate[1,]
  JournalPubDF[JPNode,1] <- JPNode
  #JournalPubDF <- JournalPubDF[!duplicated(JournalPubDF$ISSN), ]

  
  # JOURNAL
  JournalNode <- parseJournal(Journal)
  pk.JournalNode <- rowExists(JournalNode, JournalDF[,1:ncol(JournalDF)])
  if(pk.JournalNode == 0){
   JNode <- nrow(JournalDF) + 1
   JournalDF[JNode,1:ncol(JournalDF)] <- JournalNode[1,]
   JournalDF[JNode,1] <- JNode
  }
    JournalDF <- JournalDF[!duplicated(JournalDF$ISSN), ]

  #AFFILIATION
  Affiliation <- parseAffiliation(Article)
  AFFNode <- nrow(AffiliationDF) + 1
  AffiliationDF[AFFNode,1:ncol(AffiliationDF)] <- Affiliation[1,]
  AffiliationDF[AFFNode,1] <- AFFNode
  
  #AUTHORS
  Authors <- parseAuthors(Article)
  #for each row in author node
  for(n in 1:nrow(Authors)){
    #pk.AuthNode <- rowExists(Authors, AuthorDF[,1:ncol(AuthorDF)])
    # set PK using PartNumber attribute in <item> 
    #if(pk.AuthNode == 0){
      AuthNode <- nrow(AuthorDF) + 1
      AuthorDF[AuthNode,1:ncol(AuthorDF)] <- Authors[1,]
      AuthorDF[AuthNode,1] <- AuthNode
   # }
  }
  
  #SubmissionDATE
  SubmissionDate <- parseSubmissionDate(MedlineCitation)
  SubNode <- nrow(SubmissionDateDF) + 1
  SubmissionDateDF[SubNode,1:ncol(SubmissionDateDF)] <- SubmissionDate[1,]
  SubmissionDateDF[SubNode,1] <- SubNode
  
  #ARTICLE
  Article <- parseArticle(aPA)
  ArtNode <- nrow(ArticleDF) + 1
  ArticleDF[ArtNode,1:ncol(ArticleDF)] <- Article[1,]
  ArticleDF[ArtNode,1] <- ArtNode
  
 #Remove Duplicates
  AuthorDF <- AuthorDF[!duplicated(AuthorDF$LastName), ]

 # #Aff Join
 # AffiliationJoin <- parseAffiliationJoin(Article)
 # AffJNode <- nrow(AffJoinDF) + 1
 #   AffJoinDF[AffJNode,1:ncol(AffJoinDF)] <- AffiliationJoin[1,]
 #   AffJoinDF[AffJNode,1] <- AffJNode

 #AuthJoin 
}
```


#Xpath query to get the object which is a nested object. 
#Once you get the journal objects, 
# ISSN = jnode$ISSN
# Get individual attributes for xml node (.aatrs for that node)
```{r}
dbExecute(dbcon,
         "DROP SCHEMA IF EXISTS starschema;" )
```

```{r}

dbWriteTable(dbcon, "Author", AuthorDF, append = T)
dbWriteTable(dbcon, "Journal", JournalDF, append = T)
dbWriteTable(dbcon, "JournalPub", JournalPubDF, append = T)
dbWriteTable(dbcon, "SubmissionDate", SubmissionDateDF, append = T)
dbWriteTable(dbcon, "Affiliation", AffiliationDF, append = T)
dbWriteTable(dbcon, "Article", ArticleDF, append = T)

```

######################## 

```{sql connection=dbcon}
DROP TABLE IF EXISTS FactTableBase
```
#Create tables for relational schema


## JOURNAL
```{sql connection=dbcon}
CREATE TABLE FactTableBase(
  ISSN VARCHAR(20),
  ArticleCount INTEGER,
  dateDiscrepency INTEGER,
  Published Date,
  CONSTRAINT ISSN_pk PRIMARY KEY (ISSN)
)
```

# Create DataFrame
```{r}
FactTableDF <- data.frame( 
                            ISSN = character(),
                            ArticleCount = integer(),
                            DateDiscrepencyDF = integer(),
                            Published = character(),
                            stringsAsFactors = F)
```

# Create DD table
```{r}
 DateDiscrepencyDF <- data.frame( ISSNDate = character(), Published = character(), Submitted = character(), Diff = integer())
```
# Set ISSN
```{r}
ISSNDate <- sqldf("SELECT a.ISSN
 From ArticleDF a")
```
# Import ISSN
```{r}
DateDiscrepencyDF <- data.frame( ISSNDate)
```
# Add published
```{r}
DateDiscrepencyDF$Published <- paste(JournalPubDF$Year, JournalPubDF$Month, JournalPubDF$DayNum, sep="-") %>% ymd() %>% as.Date()
```
# Add Submitted
```{r}
DateDiscrepencyDF$Submitted <- paste(SubmissionDateDF$Year, SubmissionDateDF$Month, SubmissionDateDF$Day, sep="-") %>% ymd() %>% as.Date()
```
# Calculate difference - Cite Stack overflow
```{r}
DateDiscrepencyDF$Diff <- DateDiscrepencyDF$Published - DateDiscrepencyDF$Submitted
```
# GROUP BY a.ISSN
```{r}
 ftISSN <- sqldf("SELECT a.ISSN
 From ArticleDF a
 GROUP BY a.ISSN")
 
 ftCount <- sqldf("SELECT COUNT(a.ISSN)
 From ArticleDF a
 GROUP BY a.ISSN")

 ftDateDiscrepency <- sqldf("SELECT AVG(d.Diff)
                            FROM DateDiscrepencyDF d
                            GROUP BY d.ISSN")
 
 ftPublished <- sqldf("SELECT d.Published
                      FROM DateDiscrepencyDF d
                      GROUP BY d.ISSN")
```

```{r}
 FactTableDF <- data.frame(ftISSN, ftCount, ftDateDiscrepency, ftPublished)
```

```{r}
colnames(FactTableDF) <- c('ISSN','ArticleCount','dateDiscrepency', 'Published')
```

## IMPORTANT NOTE: The Instructions specifically said use Journal pub date and date created. This can lead to some strange results.

# Write to MYSQL
```{r}
dbWriteTable(dbcon, "FactTableBase", FactTableDF, append = T)
```


# Part 2 (40 pts) Create Star/Snowflake Schema
## (40 pts) Create and populate a star schema with dimension and summary fact tables in either SQLite or MySQL. Each row in the fact table will represent one journal fact. It must include (minimally) the journal id, number of articles, and the average number of days elapsed between submission (date created in the XML) and date of publication in the journal by by year and by quarter. 


#Add a few additional facts that are useful for future analytics. Populate the star schema via R. When building the schema, look a head to Part 3 as the schema is dependent on the eventual OLAP queries. Note that there is not a single way to create the fact table -- you may use dimension tables or you may collapse the dimensions into the fact table. Remember that the goal of fact tables is to make interactive analytical queries fast through pre-computation and storage -- more storage but better performance. This requires thinking and creativity -- there is not a single best solution.

#Structure- four dimension tables that allow me to store premade queries. 
#Article, PubDate, Journal, Submission Date

# DB EXECUTE to store the fact table
```{r}
dbExecute(dbcon,
         "CREATE SCHEMA IF NOT EXISTS starschema;" )
```
# Use Starchema
```{r}
dbExecute(dbcon,"USE starschema;")
```
#DropTables Section
```{r}
dbExecute(dbcon,
         "DROP TABLE IF EXISTS starschema.ArticleDim;" )
```
```{r}
dbExecute(dbcon,
         " DROP TABLE IF EXISTS starschema.JournalDim;
" )
```
```{r}
dbExecute(dbcon,
         " DROP TABLE IF EXISTS starschema.PublishedDim;
" )
```
```{r}
dbExecute(dbcon,
         " DROP TABLE IF EXISTS starschema.SubmittedDim;
" )
```

```{r}
dbExecute(dbcon,
         " DROP TABLE IF EXISTS starschema.FactTableDim;
" )
```

```{r}
dbExecute(dbcon, "DROP TABLE IF EXISTS starschema.ArticlesPerJournal;")
```


# Create Dimension tables for potental future use
```{r}
starschema.ArticleDim <- dbExecute(dbcon,
         " CREATE TABLE starschema.ArticleDim
   AS SELECT rid AS Articledim_key,ArticleTitle,ArticleDate,pid,ISSN FROM PubMed.Article;" )
```

```{r}
starschema.JournalDim <- dbExecute(dbcon,
         " CREATE TABLE starschema.JournalDim
   AS SELECT ISSN AS Journaldim_key, Volume, Issue FROM PubMed.Journal;" )
```

```{r}
starschema.JournalDim <- dbExecute(dbcon,
         " CREATE TABLE starschema.FactTableDim
   AS SELECT ISSN AS FactTabledim_key, ArticleCount, dateDiscrepency, Published FROM PubMed.FactTableBase;" )
```

```{r}
starschema.PublishedDim <- dbExecute(dbcon,
         "CREATE TABLE starschema.PublishedDim(
   Publisheddim_Key int NOT NULL AUTO_INCREMENT PRIMARY KEY, 
   day_num INT,
   month_num INT, 
   year_num INT,
   ISSN VARCHAR(10),
   part_of_year VARCHAR(10)
   );")
```

```{r}
dbExecute(dbcon,
         "INSERT INTO starschema.PublishedDim (month_num, year_num, day_num, ISSN, part_of_year)
  SELECT Month AS month_num, Year AS year_num, DayNum as day_num, ISSN as ISSN,
    CASE 
	   WHEN Month < 12 AND Month > 8 THEN 'Fall'
       WHEN Month < 9 AND Month > 5 THEN 'Summer'
       WHEN Month < 6 AND Month > 2 THEN 'Spring'
       When Month < 3 THEN 'Winter'
       ELSE 'Winter'
     END
  From PubMed.JournalPub;
  " )
```

```{r}
starschema.SubmittedDim <- dbExecute(dbcon,
         "  CREATE TABLE starschema.SubmittedDim(
   Submissiondim_key int NOT NULL AUTO_INCREMENT PRIMARY KEY,
   day_num INT,
   month_num INT, 
   year_num INT,
   part_of_year VARCHAR(20)
   );" )
```

```{r}
dbExecute(dbcon,
         "INSERT INTO starschema.SubmittedDim (month_num, year_num, day_num, part_of_year)
  SELECT Month AS month_num, Year AS year_num, Day as day_num,
    CASE 
	     WHEN Month < 12 AND Month > 8 THEN 'Fall'
       WHEN Month < 9 AND Month > 5 THEN 'Summer'
       WHEN Month < 6 AND Month > 2 THEN 'Spring'
       When Month < 3 THEN 'Winter'
       ELSE 'Winter'
     END
  From PubMed.SubmissionDate;" )
```

#dimanesion and Summary fact tables
  #Dimension
  #Journal ID
  #Number of articles
  #average days elapsed (Submission / Published)

```{r}
dbExecute(dbcon,
         " CREATE TABLE starschema.ArticlesPerJournal (
FactTabledim_key INT,
Publisheddim_Key INT,
CONSTRAINT PRIMARY KEY (FactTabledim_key, Publisheddim_Key )
);" )
```


```{r}
Season <- sqldf( "
     SELECT Month, ISSN as ISSN,
    CASE 
	   WHEN Month < 12 AND Month > 8 THEN 'Fall'
       WHEN Month < 9 AND Month > 5 THEN 'Summer'
       WHEN Month < 6 AND Month > 2 THEN 'Spring'
       When Month < 3 THEN 'Winter'
       ELSE 'Winter'
     END
  From JournalPubDF
  Group BY ISSN;")
```

```{r}
FactTableDF$Season <- Season$`CASE 
	   WHEN Month < 12 AND Month > 8 THEN 'Fall'
       WHEN Month < 9 AND Month > 5 THEN 'Summer'
       WHEN Month < 6 AND Month > 2 THEN 'Spring'
       When Month < 3 THEN 'Winter'
       ELSE 'Winter'
     END`
```

## FACT TABLE
```{r}
FactTableDF <-FactTableDF[!(FactTableDF$dateDiscrepency<0 | FactTableDF$dateDiscrepency==0),]
FactTableDF

```


# Part 3 (20 pts) Explore and Mine Data
## (20 pts) Write queries using your data warehouse to populate a fictitious dashboard that would allow an analyst to explore whether the number of publications show a seasonal pattern. 
#Create a line graph that shows the average days elapsed between submission and publication for all journals per quarter. If necessary, adjust your fact table(s) as needed to support your new queries. If you need to update the fact table, document your changes and your reasons why the changes are needed. This requires thinking and creativity -- there is not a single best solution.

# I need to update my fact table to show average days elapsed, I can do that using the diftime() and plot that
# Once the dates were sorted and appropriately compared, I added the Season.I did this for fun and to proce the snowflake schema works!
# Wrote a ton of Dimension and fact tables above to address the first part of the question, but here is another one!

```{r}
SeasonToPublish <- sqldf( "
     SELECT Season, Count(Season)
  From FactTableDF
  Group BY Season;")

SeasonToPublish
```


#Line graph, publication date is x, y = average days elapsed


```{r}
ggplot(data=FactTableDF, aes(x=Season, y=dateDiscrepency, group=1)) +
  geom_line(color="red")+
  geom_point() +
  labs(x = "Season", y = "Days Elapsed") +
  labs(title = "Publications Through the Seasons")
```

```{r}
dbDisconnect(dbcon)
```



